---
title: "STATS 506 HW4"
author: "Zongyi Liu"
date: "2023-10-12"
output:
  pdf_document: default
  html_document: default
---

Github repo: <https://github.com/PKUniiiiice/STATS_506>

## Problem 1

### (a)

```{r , warning=FALSE}
library(nycflights13)
library(tidyverse)
data("airlines","airports", "flights", "planes", "weather")
```

```{r p1aa}
#left join flights and airports to get airport
t1 <- left_join(flights, airports, by=join_by(`origin` == `faa`))

#define a function at first
delay_smy <- function(data, varb) {
  data %>%
    group_by(name) %>%
    summarise(
      Mean_delay = mean({{varb}}, na.rm = TRUE),
      Median_delay = median({{varb}}, na.rm = TRUE)
    ) %>%
    ungroup()
}
#Generate a table (which can just be a nicely printed tibble) reporting the mean and median departure delay per airport.
smy1 <- flights %>% 
        left_join(airports, by=c("origin" = "faa")) %>% 
        delay_smy(varb=`dep_delay`) %>% 
        arrange(desc(Mean_delay)) %>% 
        na.omit() %>% 
        print(n = Inf)

#Generate a second table (which again can be a nicely printed tibble) reporting the mean and median arrival delay per airport.
#we use filter to exclude
smy2 <- flights %>% 
        left_join(airports, by=c("dest" = "faa")) %>% 
        delay_smy(varb=`arr_delay`) %>% 
        filter(n()>=10) %>% 
        arrange(desc(Mean_delay)) %>% 
        na.omit() %>% 
        print(n = Inf)

```

### (b)

```{r p1b}
#find the fastest speed model
# we should calculate the average speed manually, can't use the speed variable in table planes, since there are too many missing values in the column.
# we use air time and distance in table flights to calculate average speed
fastest <- flights %>% 
      left_join(planes, by=c("tailnum")) %>% 
      select(air_time, distance, model) %>% 
      na.omit() %>% #filter missing at first
      group_by(model) %>% 
      summarise(
         air_time = sum(air_time, na.rm=TRUE)/60, #convert to hour
         distance = sum(distance, na.rm=TRUE),
         avg_speed = distance/air_time,
         n = n()
      ) %>% 
      ungroup() %>% 
      arrange(desc(avg_speed)) %>% 
      select(model, avg_speed, n) %>% 
      print(n=1)

```

## Problem 2

```{r p2}
nnmaps <- read.csv("./chicago-nmmaps-custom.csv", header=TRUE) %>% tibble()

#' Allows a user to request the average temperature for a given month.
#' 
#' @param month Month, either a numeric 1-12 or a string.
#' @param year A numeric year.
#' @param data The data set to obtain data from.
#' @param celsius Logically indicating whether the results should be in celsius. Default FALSE.
#' @param average_fn A function with which to compute the mean. Default is mean.
get_temp <- function(month, year, data, celsius=FALSE, average_fn=mean){

  #check input -- month
  if ( !(is.character(month) || is.numeric(month) ) )
    stop("Month should be a valid string (e.g., 'Jan') or a numeric value (1-12).")
  else if (is.character(month)){
    if (is.na( mat <- match(month, c(month.abb, month.name))))
        stop("Month should be a valid string (e.g., 'Jan') or a numeric value (1-12).")
    else
      month.clr <- ifelse(mat<13, mat, mat-12)
  }
  else{
    if( !(month.clr <-month) %in% seq(1, 12))
      stop("Month should be a valid string (e.g., 'Jan') or a numeric value (1-12).")
  }

  #check input -- year
  if ( ! (is.numeric(year) && (year>0) && (year%%1==0)))
    stop("Year, must a positive numeric (integer) value.")
  year.clr <- as.integer(year)
  
  #check input -- data
  if (!is.data.frame(data))
    stop("data, must be a data.frame or tibble.")
  
  #check input -- celsius
  if (!is.logical(celsius))
    stop("data, must be TRUE or FALSE")
  
  if (!is.function(average_fn))
    stop("average_fn, must be a function")

  out <- data %>% 
         filter(month==month.abb[month.clr],
                year==year.clr) %>% 
         summarise(
           temp = average_fn(temp)
         ) %>% 
         mutate(
           celsius.avg = (temp-32)/1.8
         ) %>% 
         select(ifelse(celsius, 2, 1)) %>% 
         pull()
  if (is.na(out))
    stop("Average temperature is NaN. 2 common reasons are
         1. The requested data is missing in the dataset.
         2. There may be an issue with the customed average function.")
  return (out)
}

#test
try(get_temp("Apr", 1999, data = nnmaps))
try(get_temp("Apr", 1999, data = nnmaps, celsius = TRUE))
try(get_temp(10, 1998, data = nnmaps, average_fn = median))
try(get_temp(13, 1998, data = nnmaps))
try(get_temp(2, 2005, data = nnmaps))
try(get_temp("November", 1999, data =nnmaps, celsius = TRUE,
         average_fn = function(x) {
           x %>% sort -> x
           x[2:(length(x) - 1)] %>% mean %>% return
         }))
```

## Problem 3

SAS results: <https://github.com/PKUniiiiice/STATS_506/blob/main/HW4/hw4p3-result.html>.

### (a)

``` sas
options locale = EN_US;
/* we use the file my_shared_file_links/jbhender0/input_data/recs2020_public_v5.sas7bdat*/

/* data library for reading/writing data: ---------------------------------- */
%let out_path = ~/hw4/output_data;
libname out_lib "&out_path.";

data recs2020;
    set "/home/u63640224/my_shared_file_links/jbhender0/input_data/recs2020_public_v5.sas7bdat";
run;

/* We use nweight as sampling weight */
proc summary data=recs2020;
  class state_name;
  output out=out_lib.records_by_state
         sum(nweight) = num;
run;

/* calculate percentage */
proc sql;
    create table out_lib.records_percentage as
    select state_name,
           num,
           num / sum(num) * 100 as percentage
    from out_lib.records_by_state
    where _type_ = 1
    order by percentage desc;
quit;

/* get highest percentage */
proc print data=out_lib.records_percentage (obs=1);
run;

/* get michigan percentage */
proc sql;
    select *
    from out_lib.records_percentage
    where state_name="Michigan";
quit;
```

From the result, California has the highest percentage of records (10.67%). Michigan's percentage is 3.17%.

### (b)

``` sas
/* we use DOLLAREL to calculate total electricity cost */
proc sql;
  create table PositiveCost as
  select DOLLAREL, log(DOLLAREL) as logDOLLAREL
  from recs2020
  where DOLLAREL > 0;
quit;

proc sgplot data=PositiveCost;
  histogram DOLLAREL / binwidth=200 legendlabel="Total Electricity Cost (Dollars)";
  xaxis label="Total Electricity Cost (Dollars)";
  yaxis label="Frequency";
run;
```

### (c)

``` sas
proc sgplot data=PositiveCost;
  histogram logDOLLAREL / binwidth=0.2 legendlabel="Log of Total Electricity Cost (Dollars)";
  xaxis label="Log of Total Electricity Cost (Dollars)";
  yaxis label="Frequency";
run;
```

### (d)

``` sas
/* we use total number of rooms (TOTROOMS)
        + number full bathrooms (NCOMBATH)
        + number of half bathrooms (NHAFBATH)
        as number of rooms in the house,
   we use PRKGPLC1 to reprsent whether the house has a garage
   we delete all missing values.
   we use nweight as sampling weight  
   we use DOLLAREL to calculate total electricity cost */
   
/* create data set */

proc sql;
  create table out_lib.regress_elec as
  select TOTROOMS,
         NCOMBATH,
         NHAFBATH,
         PRKGPLC1,
         NWEIGHT,
         log(DOLLAREL) as logDOLLAREL
  from recs2020
  where PRKGPLC1 <> -2; /* missing value of garage */
quit;

/* drop missing value of other variables */
data out_lib.regress_elec;
  set out_lib.regress_elec;
  if cmiss(of _all_) then delete;
run;

/* get total rooms */
data out_lib.regress_elec;
  set out_lib.regress_elec;
  num_rooms = TOTROOMS+NCOMBATH+NHAFBATH;
run;

/*regression*/
proc reg data=out_lib.regress_elec;
  model logDOLLAREL = num_rooms PRKGPLC1;
  output out=pred predicted=p;
  weight NWEIGHT;
run;

/* just try
proc glm data=out_lib.regress_elec;
  class PRKGPLC1;
  model logDOLLAREL = num_rooms PRKGPLC1;
  weight NWEIGHT;
run;
*/
```

### (e)

``` sas
/*create a new dataset with actual and predicted values */
data pred;
  set pred;
  Actual_DOLLAREL = exp(logDOLLAREL); /* convert back to the original scale */
  Pred_DOLLAREL = exp(p);
run;

/* create a scatterplot of predicted vs. actual values */
proc sgplot data=pred;
  scatter x=Actual_DOLLAREL y=Pred_DOLLAREL;
  xaxis label="Actual Total Electricity Cost (Dollars)";
  yaxis label="Predicted Total Electricity Cost (Dollars)";
run;
```

## Problem 4

### (a)

This codebook was generated by Stata, as it utilizes data types such as "byte," "int," and "long" to represent various levels of integer precision. Furthermore, by directly referring to <https://www.stata.com/manuals/dcodebook.pdf>, you can confirm that the format aligns with the SHED codebook.

### (b) and (c)

``` sas
/* We use
B3: Compared to 12 months ago, would you say that you (and your family) are better off, the same, or worse off financially?
ND2: Five years from now, do you think that the chance that you will experience a natural disaster or severe weather event will be higher, lower or about the same as it is now?
B7_b: In this country -How would you rate economic conditions today
GH1: This section will ask some questions about your home and your car. Do you (and/or your spouse or partner) (require modify)
ppeducat: Education (4 Categories)
ppethm  Race / Ethnicity 
Moreover, we need weight for this survey
    Weight_pop is most commonly used and includes the weights used for the "Economic Well-Being of U.S. Households in 2022." 
    These weights allow for the entire sample to reflect the observable characteristics of the U.S. adult population. 
    They are scaled to add up to the total population of the U.S. adults eligible for this survey.
So we use weight_pop
And we need CaseID
*/
%let out_path = ~/hw4/output_data;
libname out_lib "&out_path.";

data public2022;
    set "/home/u63640224/hw4/public2022.sas7bdat";
run;

proc sql;
    create table out_lib.variables_req as 
    select CaseID, /*no nan*/
           B3 as family_finan,  /*no nan*/
           ND2 as nature_disa,  /*no nan*/
           B7_b as econ_cond,   /*no nan*/
           case 
                when GH1=1 or GH1=2 then 1 /*own*/
                when GH1=3 then 2 /*pay rent*/
                else 3 /*neither*/  
                end as home_have,   /*no nan*/
           ppeducat as education, /*no nan*/
           ppethm as race, /*no nan*/
           weight_pop as weight /*no nan*/
           from public2022;
quit;

/* Now, for (c), downloading the file "out_lib.variables_req" is enough. */
```

### (d)

``` stata
. // load data to stata
. clear

. import sas CaseID family_finan nature_disa econ_cond home_have education race weight using "K:\STATS_506\
> STATA\variables_req.sas7bdat"
(8 vars, 11,667 obs)

. 
. describe

Contains data
 Observations:        11,667                  
    Variables:             8                  
-----------------------------------------------------------------------------------------------------------
Variable      Storage   Display    Value
    name         type    format    label      Variable label
-----------------------------------------------------------------------------------------------------------
CaseID          int     %10.0g                CaseID 2022
family_finan    byte    %10.0g                Compared to 12 months ago, would you say that you (and your
                                                family) are better o
nature_disa     byte    %10.0g                Five years from now, do you think that the chance that you
                                                will experience a nat
econ_cond       byte    %10.0g                In this country - How would you rate economic conditions
                                                today:
home_have       byte    %10.0g                
education       byte    %10.0g                Education (4 Categories)
race            byte    %10.0g                Race / Ethnicity
weight          double  %10.0g                Post-stratification weight - Main qualified respondents
                                                scaled to U.S. populatio
-----------------------------------------------------------------------------------------------------------
Sorted by: 
     Note: Dataset has changed since last saved.
```

### (e)

``` stata
. 
. //B3 has 5 levels, 1 and 2 are worse off --- convert to 0
. //3,4,5 are the same or better off --- convert to 1
. recode family_finan (1/2=0) (3/5=1), gen(family_finan_bin)
(11,667 differences between family_finan and family_finan_bin)

. 
. 
```

### (f)

We calculate both coefficients and odds ratios for the logistic regression model.

``` stata
. //question f
. svyset CaseID [pw=weight]

Sampling weights: weight
             VCE: linearized
     Single unit: missing
        Strata 1: <one>
 Sampling unit 1: CaseID
           FPC 1: <zero>

. 
. //f cond
. // nature_disa is natural ordered -- small value -- higher chance
. // note that econ_cond is natural ordered large value -- good condition
. // home_have is nominal categorical
. // education is natural oreder, large value -- high education level
. // race is nominal
. svy: logistic family_finan_bin nature_disa econ_cond i.home_have education i.race
(running logistic on estimation sample)

Survey: Logistic regression

Number of strata =      1                        Number of obs   =      11,667
Number of PSUs   = 11,667                        Population size = 255,114,223
                                                 Design df       =      11,666
                                                 F(9, 11658)     =       94.24
                                                 Prob > F        =      0.0000

----------------------------------------------------------------------------------
                 |             Linearized
family_finan_bin | Odds ratio   std. err.      t    P>|t|     [95% conf. interval]
-----------------+----------------------------------------------------------------
     nature_disa |   1.033374   .0315333     1.08   0.282     .9733756    1.097071
       econ_cond |   2.650293   .0966773    26.72   0.000     2.467406    2.846736
                 |
       home_have |
              2  |   1.053186   .0572268     0.95   0.340     .9467788    1.171552
              3  |    1.45047   .1405322     3.84   0.000      1.19958    1.753831
                 |
       education |    1.09333   .0267164     3.65   0.000     1.042195    1.146973
                 |
            race |
              2  |   2.041822   .1646132     8.85   0.000     1.743357    2.391385
              3  |   1.437889   .1698341     3.07   0.002     1.140713    1.812484
              4  |   1.181915   .0838862     2.35   0.019      1.02841    1.358334
              5  |   .9095113   .1236092    -0.70   0.485     .6968056    1.187147
                 |
           _cons |   .2050857   .0276544   -11.75   0.000     .1574507    .2671321
----------------------------------------------------------------------------------
Note: _cons estimates baseline odds.

. 
. 
. svy: logit family_finan_bin nature_disa econ_cond i.home_have education i.race
(running logit on estimation sample)

Survey: Logistic regression

Number of strata =      1                        Number of obs   =      11,667
Number of PSUs   = 11,667                        Population size = 255,114,223
                                                 Design df       =      11,666
                                                 F(9, 11658)     =       94.24
                                                 Prob > F        =      0.0000

----------------------------------------------------------------------------------
                 |             Linearized
family_finan_bin | Coefficient  std. err.      t    P>|t|     [95% conf. interval]
-----------------+----------------------------------------------------------------
     nature_disa |   .0328291   .0305149     1.08   0.282    -.0269852    .0926435
       econ_cond |   .9746702    .036478    26.72   0.000     .9031672    1.046173
                 |
       home_have |
              2  |   .0518196   .0543369     0.95   0.340    -.0546898     .158329
              3  |   .3718874   .0968874     3.84   0.000     .1819719    .5618028
                 |
       education |   .0892277   .0244358     3.65   0.000     .0413294    .1371259
                 |
            race |
              2  |   .7138425   .0806207     8.85   0.000     .5558123    .8718726
              3  |   .3631758   .1181135     3.07   0.002     .1316536    .5946981
              4  |   .1671364   .0709748     2.35   0.019      .028014    .3062588
              5  |  -.0948479   .1359072    -0.70   0.485    -.3612488     .171553
                 |
           _cons |  -1.584327   .1348433   -11.75   0.000    -1.848643   -1.320012
----------------------------------------------------------------------------------

. //install outreg2
. //ssc install outreg2
. 
. //extract model result
. //outreg2 using "K:\STATS_506\STATA\model_results.csv", replace
. 
end of do-file
```

We found that when we control for economic conditions, home ownership, education, and race, the odds ratio for the respondent's belief of natural disasters is 1.033374. This value is only slightly higher than 1, which means that a one-unit increase (indicating a lower belief of experiencing a natural disaster) is associated with a slight increase in the odds of their family being in a better financial condition (multiplied by 1.033). In other words, if the respondent believes the chance of a natural disaster is lower, their family's financial situation is likely to be better.

However, it's important to note that the p-value for `nature_disa` is 0.28, which is greater than the typical significance level of 0.05. This indicates that this coefficient is not statistically significant. Additionally, the odds ratio's magnitude is small. Therefore, we can conclude that it's **unlikely** that we can predict whether a respondent's family is financially better, the same, or worse off compared to 12 months ago based on their perception of the likelihood of future natural disasters. The statistical evidence does not support a significant relationship.

### (g)

``` stata
. //save coded version
. save "K:\STATS_506\STATA\variables_req.dta"
```

### (h)

```{r}
library(haven)
library(survey)
stata_data <- read_stata("variables_req.dta")

desg <- svydesign(id = ~ CaseID, weight = ~ weight, data = stata_data)

m1 <- svyglm(family_finan_bin ~ nature_disa + econ_cond +
                                as.factor(home_have) + education + 
                                as.factor(race), design=desg, family=quasibinomial())
summary(m1)

psrsq(m1)
```

We observe that R gives the same fitting results as stata.

The pseudo-$R^2$ is 0.1069493.
